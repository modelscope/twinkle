# 魔搭官方环境

在 Twinkle 框架开源的同时，我们在[魔搭社区官网](https://www.modelscope.cn)上提供了样例训练资源。开发者可以通过ModelScope Token进行训练。

目前在集群中运行的模型是[Qwen/Qwen3-30B-A3B-Instruct-2507](https://www.modelscope.cn/models/Qwen/Qwen3-30B-A3B-Instruct-2507)。下面介绍具体的使用方法：

## Step 1. 注册魔搭用户

开发者首先需要注册成为魔搭用户，使用魔搭社区的 token 进行调用。

注册地址：https://www.modelscope.cn/

调用端点：https://www.modelscope.cn/twinkle

token 在这里获取：https://www.modelscope.cn/my/access/token 拷贝访问令牌。

## Step 2. 加入 twinkle-explorers 组织

目前 twinkle-kit 的远程训练能力在灰度测试中，开发者需要加入 [twinkle-explorers](https://www.modelscope.cn/models/twinkle-explorers) 组织，组织内的用户可以进行使用和测试。

## Step 3. 查看 Cookbook 并二次定制开发

我们强烈推荐开发者查看我们的 [cookbook](https://github.com/modelscope/twinkle/tree/main/cookbook/client/)，并根据其中的训练代码进行二次开发。

开发者可以定制数据集/优势函数/奖励/模板等，其中 Loss 部分由于需要在服务端执行，因此当前暂不支持（安全性原因）。
如果需要支持您的额外 Loss，可以将该 Loss 实现上传到 ModelHub 中，并在答疑群中或者 issue 中联系我们，将对应组件开放白名单即可使用。

## 附录：支持的训练方式

该模型为纯文本模型，因此暂不支持多模态任务。在纯文本任务中，你可以训练：

1. PT/SFT的常规训练方法，包含Agentic训练
2. GRPO/RLOO等自采样RL算法
3. GKD/On-policy等蒸馏方法，由于魔搭官方端仅支持单模型，因此另一个Teacher/Student模型需要开发者自行准备

当前官方环境仅支持LoRA训练，对LoRA的要求：

1. 最大rank=32
2. 不支持modules_to_save
