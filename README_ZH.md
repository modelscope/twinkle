<h1 align="center">Twinkle: <b>T</b>raining <b>W</b>orkbench for <b>I</b>ndustrial <b>N</b>eural-network <b>K</b>it & <b>L</b>LM <b>E</b>ngineering</h1>

<p align="center">
    <br>
    <img src="assets/slogan.png"/>
    <br>
<p>
<p align="center">
<a href="https://modelscope.cn/home">The Modelscope Community</a>
<br>
        ä¸­æ–‡&nbsp ï½œ &nbsp<a href="README.md">English</a>&nbsp
</p>

<p align="center">
<img src="https://img.shields.io/badge/python-3.11-5be.svg">
<img src="https://img.shields.io/badge/pytorch-%E2%89%A52.0-orange.svg">
<a href="https://pypi.org/project/twinkle/"><img src="https://badge.fury.io/py/twinkle.svg"></a>
<a href="https://github.com/modelscope/twinkle/blob/main/LICENSE"><img src="https://img.shields.io/github/license/modelscope/twinkle"></a>
<a href="https://pepy.tech/project/twinkle-kit"><img src="https://pepy.tech/badge/twinkle-kit"></a>
<a href="https://github.com/modelscope/twinkle/pulls"><img src="https://img.shields.io/badge/PR-welcome-55EB99.svg"></a>
</p>

<p align="center">
        <a href="https://twinkle-kit.readthedocs.io/en/latest/">English Documentation</a> &nbsp ï½œ &nbsp <a href="https://twinkle-kit.readthedocs.io/zh-cn/latest/">ä¸­æ–‡æ–‡æ¡£</a> &nbsp
</p>

<div align="center">

## âœ¨ Twinkleæ˜¯ä»€ä¹ˆï¼Ÿ

å¤§æ¨¡å‹è®­ç»ƒç»„ä»¶åº“ã€‚åŸºäº PyTorchï¼Œæ›´ç®€æ´ã€æ›´çµæ´»ã€ç”Ÿäº§å°±ç»ªã€‚

<p align="center">
ğŸ§© <b>æ¾è€¦åˆæ¶æ„</b> Â· æ ‡å‡†åŒ–æ¥å£<br>
ğŸš€ <b>å¤šè¿è¡Œæ¨¡å¼</b> Â· torchrun / Ray / HTTP<br>
ğŸ”Œ <b>å¤šæ¡†æ¶å…¼å®¹</b> Â· Transformers / Megatron<br>
ğŸ‘¥ <b>å¤šç§Ÿæˆ·æ”¯æŒ</b> Â· å•åŸºåº§æ¨¡å‹éƒ¨ç½²
</p>

</div>

## å®‰è£…

ä½¿ç”¨pipå®‰è£…ï¼š

```shell
pip install 'twinkle-kit'
```

## æºä»£ç å®‰è£…

```shell
git clone https://github.com/modelscope/twinkle.git
cd twinkle
pip install -e . --no-build-isolation
```

## ç¤ºä¾‹æ•™ç¨‹

| è®­ç»ƒç±»å‹                          | æ¨¡å‹æ¡†æ¶     | cookbookåœ°å€                             |
| --------------------------------- | ------------ | ---------------------------------------- |
| FSDP finetuning                   | transformers | [è„šæœ¬](cookbook/transformers/fsdp2.py)      |
| FSDP MoE finetuning               | transformers | [è„šæœ¬](cookbook/transformers/fsdp2_moe.py)  |
| EP MoE finetuning                 | transformers | [è„šæœ¬](cookbook/transformers/ep_fsdp_qwen3_moe.py) |
| pp/tp/cp finetuning               | megatron     | [è„šæœ¬](cookbook/megatron/tp.py)             |
| pp/tp/cp MoE finetuning           | megatron     | [è„šæœ¬](cookbook/megatron/tp_moe.py)         |
| tinker client finetuning          | megatron     | [è„šæœ¬](cookbook/client/tinker/megatron)     |
| tinker client finetuning/sampling | transformers | [è„šæœ¬](cookbook/client/tinker/transformer)  |
| twinkle client finetuning         | megatron     | [è„šæœ¬](cookbook/client/twinkle/megatron)    |
| twinkle client finetuning         | transformer  | [è„šæœ¬](cookbook/client/twinkle/transformer) |

## æ›´æ–°æ—¥å¿—

- ğŸ‰2026-02-10 twinkle-kitç¬¬ä¸€ç‰ˆç¼–å†™å®Œæˆï¼ŒåŒ…å«çº¯æ–‡æœ¬æ¨¡å‹SFT/PT/RLå’Œè¿œç¨‹è®­ç»ƒèƒ½åŠ›ï¼Œå¹¶æ”¯æŒäº†[é­”æ­å®˜æ–¹å…è´¹èµ„æº]()

## æ”¯æŒçš„ç¡¬ä»¶

| ç¡¬ä»¶ç¯å¢ƒ                    | å¤‡æ³¨                              |
| --------------------------- | --------------------------------- |
| GPU A10/A100/H100/RTXç³»åˆ—ç­‰ |                                   |
| GPU T4/V100ç­‰               | ä¸æ”¯æŒbfloat16ã€Flash-Attention   |
| Ascend NPU                  | éƒ¨åˆ†ç®—å­ä¸æ”¯æŒ                    |
| PPU                         | æ”¯æŒ                              |
| CPU                         | æ”¯æŒdatasetã€dataloaderç­‰éƒ¨åˆ†ç»„ä»¶ |

## æ”¯æŒçš„å¤§è¯­è¨€æ¨¡å‹

| Model Type          | Model ID ä¸¾ä¾‹                                                                                                          | Requires             | Support Megatron | HF Model ID                                                                                                |
| ------------------- | ---------------------------------------------------------------------------------------------------------------------- | -------------------- | ---------------- | ---------------------------------------------------------------------------------------------------------- |
| qwen2 å…¨ç³»åˆ—        | [Qwen/Qwen2-0.5B-Instruct](https://modelscope.cn/models/Qwen/Qwen2-0.5B-Instruct)Â ï½72B                                  | transformers>=4.37   | âœ”               | [Qwen/Qwen2-0.5B-Instruct](https://huggingface.co/Qwen/Qwen2-0.5B-Instruct)                                   |
|                     | [Qwen/Qwen2-72B](https://modelscope.cn/models/Qwen/Qwen2-72B)ï½72B                                                        | transformers>=4.37   | âœ”               | [Qwen/Qwen2-1.5B](https://huggingface.co/Qwen/Qwen2-1.5B)                                                     |
|                     | [Qwen/Qwen2.5-0.5B-Instruct](https://modelscope.cn/models/Qwen/Qwen2.5-0.5B-Instruct)ï½72B                                | transformers>=4.37   | âœ”               | [Qwen/Qwen2.5-0.5B-Instruct](https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct)                               |
|                     | [Qwen/Qwen2.5-0.5B](https://modelscope.cn/models/Qwen/Qwen2.5-0.5B)ï½72B                                                  | transformers>=4.37   | âœ”               | [Qwen/Qwen2.5-0.5B](https://huggingface.co/Qwen/Qwen2.5-0.5B)                                                 |
| qwen2_moe å…¨ç³»åˆ—    | [Qwen/Qwen1.5-MoE-A2.7B-Chat](https://modelscope.cn/models/Qwen/Qwen1.5-MoE-A2.7B-Chat)                                   | transformers>=4.40   | âœ”               | [Qwen/Qwen1.5-MoE-A2.7B-Chat](https://huggingface.co/Qwen/Qwen1.5-MoE-A2.7B-Chat)                             |
| qwen3 å…¨ç³»åˆ—        | [Qwen/Qwen3-0.6B-Base](https://modelscope.cn/models/Qwen/Qwen3-0.6B-Base)ï½32B                                            | transformers>=4.51   | âœ”               | [Qwen/Qwen3-0.6B-Base](https://huggingface.co/Qwen/Qwen3-0.6B-Base)                                           |
| qwen3_moe å…¨ç³»åˆ—    | [Qwen/Qwen3-30B-A3B-Base](https://modelscope.cn/models/Qwen/Qwen3-30B-A3B-Base)                                           | transformers>=4.51   | âœ”               | [Qwen/Qwen3-30B-A3B-Base](https://huggingface.co/Qwen/Qwen3-30B-A3B-Base)                                     |
|                     | [Qwen/Qwen3-30B-A3B](https://modelscope.cn/models/Qwen/Qwen3-30B-A3B)ï½235B                                               | transformers>=4.51   | âœ”               | [Qwen/Qwen3-30B-A3B](https://huggingface.co/Qwen/Qwen3-30B-A3B)                                               |
| chatglm2 å…¨ç³»åˆ—     | [ZhipuAI/chatglm2-6b](https://modelscope.cn/models/ZhipuAI/chatglm2-6b)                                                   | transformers<4.42    | âœ˜               | [zai-org/chatglm2-6b](https://huggingface.co/zai-org/chatglm2-6b)                                             |
|                     | [ZhipuAI/chatglm2-6b-32k](https://modelscope.cn/models/ZhipuAI/chatglm2-6b-32k)                                           | transformers<4.42    | âœ˜               | [zai-org/chatglm2-6b-32k](https://huggingface.co/zai-org/chatglm2-6b-32k)                                     |
| chatglm3 å…¨ç³»åˆ—     | [ZhipuAI/chatglm3-6b](https://modelscope.cn/models/ZhipuAI/chatglm3-6b)                                                   | transformers<4.42    | âœ˜               | [zai-org/chatglm3-6b](https://huggingface.co/zai-org/chatglm3-6b)                                             |
|                     | [ZhipuAI/chatglm3-6b-base](https://modelscope.cn/models/ZhipuAI/chatglm3-6b-base)                                         | transformers<4.42    | âœ˜               | [zai-org/chatglm3-6b-base](https://huggingface.co/zai-org/chatglm3-6b-base)                                   |
|                     | [ZhipuAI/chatglm3-6b-32k](https://modelscope.cn/models/ZhipuAI/chatglm3-6b-32k)~128k                                      | transformers<4.42    | âœ˜               | [zai-org/chatglm3-6b-32k](https://huggingface.co/zai-org/chatglm3-6b-32k)                                     |
| chatglm4 å…¨ç³»åˆ—     | [ZhipuAI/glm-4-9b-chat](https://modelscope.cn/models/ZhipuAI/glm-4-9b-chat)                                               | transformers>=4.42   | âœ˜               | [zai-org/glm-4-9b-chat](https://huggingface.co/zai-org/glm-4-9b-chat)                                         |
|                     | [ZhipuAI/LongWriter-glm4-9b](https://modelscope.cn/models/ZhipuAI/LongWriter-glm4-9b)                                     | transformers>=4.42   | âœ˜               | [zai-org/LongWriter-glm4-9b](https://huggingface.co/zai-org/LongWriter-glm4-9b)                               |
| glm_edge å…¨ç³»åˆ—     | [ZhipuAI/glm-edge-1.5b-chat](https://modelscope.cn/models/ZhipuAI/glm-edge-1.5b-chat)                                     | transformers>=4.46   | âœ˜               | [zai-org/glm-edge-1.5b-chat](https://huggingface.co/zai-org/glm-edge-1.5b-chat)                               |
|                     | [ZhipuAI/glm-edge-4b-chat](https://modelscope.cn/models/ZhipuAI/glm-edge-4b-chat)                                         | transformers>=4.46   | âœ˜               | [zai-org/glm-edge-4b-chat](https://huggingface.co/zai-org/glm-edge-4b-chat)                                   |
| internlm2 å…¨ç³»åˆ—    | [Shanghai_AI_Laboratory/internlm2-1_8b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-1_8b)               | transformers>=4.38   | âœ˜               | [internlm/internlm2-1_8b](https://huggingface.co/internlm/internlm2-1_8b)                                     |
|                     | [Shanghai_AI_Laboratory/internlm2-chat-7b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-chat-7b)         | transformers>=4.38   | âœ˜               | [internlm/internlm2-chat-7b](https://huggingface.co/internlm/internlm2-chat-7b)                               |
| deepseek_v1         | [deepseek-ai/deepseek-vl-7b-chat](https://modelscope.cn/models/deepseek-ai/deepseek-vl-7b-chat)                           | transformers>=4.39.4 | âœ”               | â€”â€”                                                                                                       |
|                     | [deepseek-ai/DeepSeek-V2-Lite](https://modelscope.cn/models/deepseek-ai/DeepSeek-V2-Lite)                                 | transformers>=4.39.3 | âœ”               | [deepseek-ai/DeepSeek-V2-Lite](https://huggingface.co/deepseek-ai/DeepSeek-V2-Lite)                           |
|                     | [deepseek-ai/DeepSeek-V2.5](https://modelscope.cn/models/deepseek-ai/DeepSeek-V2.5)                                       | transformers>=4.39.3 | âœ”               | [deepseek-ai/DeepSeek-V2.5](https://huggingface.co/deepseek-ai/DeepSeek-V2.5)                                 |
|                     | [deepseek-ai/DeepSeek-R1](https://modelscope.cn/models/deepseek-ai/DeepSeek-R1)                                           | transformers>=4.39.3 | âœ”               | [deepseek-ai/DeepSeek-R1](https://huggingface.co/deepseek-ai/DeepSeek-R1)                                     |
| deepSeek-r1-distill | [deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B](https://modelscope.cn/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B)Â ~32B | transformers>=4.37   | âœ”               | [deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B) |

æ›´è¯¦ç»†çš„æ¨¡å‹æ”¯æŒåˆ—è¡¨ ğŸ‘‰  [å¿«é€Ÿå¼€å§‹.md](https://github.com/modelscope/twinkle/blob/dev/docs/source/%E4%BD%BF%E7%94%A8%E6%8C%87%E5%BC%95/%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B.md)

## ç¤ºä¾‹ä»£ç 

```python
from peft import LoraConfig
import twinkle
from twinkle import DeviceMesh, DeviceGroup
from twinkle.dataloader import DataLoader
from twinkle.dataset import Dataset, DatasetMeta
from twinkle.model import TransformersModel
from twinkle.preprocessor import SelfCognitionProcessor

device_group = [DeviceGroup(name='default',ranks=8,device_type='cuda')]
device_mesh = DeviceMesh.from_sizes(fsdp_size=4, dp_size=2)
# local for torchrun
twinkle.initialize(mode='ray', groups=device_group, global_device_mesh=device_mesh)


def train():
    # 1000 samples
    dataset = Dataset(dataset_meta=DatasetMeta('ms://swift/self-cognition', data_slice=range(1000)))
    # Set template to prepare encoding
    dataset.set_template('Template', model_id='ms://Qwen/Qwen2.5-7B-Instruct')
    # Preprocess the dataset to standard format
    dataset.map(SelfCognitionProcessor('twinkleå¤§æ¨¡å‹', 'ModelScopeç¤¾åŒº'))
    # Encode dataset
    dataset.encode()
    # Global batch size = 8, for GPUs, so 1 sample per GPU
    dataloader = DataLoader(dataset=dataset, batch_size=8, min_batch_size=8)
    # Use a TransformersModel
    model = TransformersModel(model_id='ms://Qwen/Qwen2.5-7B-Instruct', remote_group='default')

    lora_config = LoraConfig(
        r=8,
        lora_alpha=32,
        target_modules='all-linear'
    )

    # Add a lora to model, with name `default`
    # Comment this to use full-parameter training
    model.add_adapter_to_model('default', lora_config, gradient_accumulation_steps=2)
    # Add Optimizer for lora `default`
    model.set_optimizer(optimizer_cls='AdamW', lr=1e-4)
    # Add LRScheduler for lora `default`
    model.set_lr_scheduler(scheduler_cls='CosineWarmupScheduler', num_warmup_steps=5,
                           num_training_steps=len(dataloader))
    for step, batch in enumerate(dataloader):
        # Do forward and backward
        model.forward_backward(inputs=batch)
        # Step
        model.clip_grad_and_step()
        if step % 20 == 0:
            # Print metric
            metric = model.calculate_metric(is_training=True)
            print(f'Current is step {step} of {len(dataloader)}, metric: {metric}')
    model.save(f'last-checkpoint')


if __name__ == '__main__':
    train()
```

è¿™æ ·å¯åŠ¨è®­ç»ƒ:

```shell
python3 train.py
```

## æ¶æ„è®¾è®¡

<img src="assets/framework.jpg" style="max-width: 500px; width: 100%;" />

twinkleçš„æ¶æ„ç”±clientå’Œserverä¸¤éƒ¨åˆ†æ„æˆï¼Œå…¶ä¸­clientç«¯åŒ…å«ä¸¤ä¸ªä½¿ç”¨å¯èƒ½æ€§ï¼š

1. ç¬¦åˆtwinkleè°ƒç”¨APIçš„å®¢æˆ·ç«¯ï¼Œå…¶APIå’Œserverç«¯å®Œå…¨ç›¸åŒ
2. å¯¹åŸç”ŸTinker APIçš„å…¼å®¹

è¿™ä½¿å¾—å¼€å‘è€…å¯ä»¥ç›´æ¥ä½¿ç”¨Tinker APIè°ƒç”¨twinkleéƒ¨ç½²èµ·æ¥çš„åç«¯è®­ç»ƒæœåŠ¡ã€‚

## å¤šç§Ÿæˆ·æ”¯æŒ

Twinkleæ”¯æŒå¤šä¸ªç§Ÿæˆ·åŒæ—¶ä½¿ç”¨ä¸€ä¸ªåŸºæ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚è¿™ä¸€è¡Œä¸ºç›®å‰ä»…é™äº[LoRA](https://github.com/huggingface/peft/blob/main/src/peft/tuners/lora/config.py#L323)ã€‚
Twinkleé‡‡ç”¨äº†LoRAæ± +ç§Ÿæˆ·ç”³è¯·çš„æŠ€æœ¯æ–¹æ¡ˆã€‚è¿™ä¸ªæ–¹æ¡ˆå¯ä»¥æ”¯æŒæœ€å¤§Nä¸ªç§Ÿæˆ·å¹¶è¡Œè®­ç»ƒäº’ä¸å¹²æ‰°ï¼Œå¹¶ä¸”åœ¨æ¨¡å‹è§’åº¦æ¥çœ‹ï¼Œä¸åŒç§Ÿæˆ·çš„è®­ç»ƒæµç¨‹å¯èƒ½ä¸åŒï¼Œåœ¨åŸºæ¨¡ä¸­çš„æ•°æ®paddingæ–¹å¼ã€optimizerã€Lossç±»å‹ä¹Ÿå¯ä»¥ä¸åŒã€‚

<img src="assets/multi_lora.png" style="max-width: 500px; width: 100%;" />

ä¾‹å¦‚ï¼š

- ç§Ÿæˆ·Aï¼šæœ¬æœºåŠ è½½æœ¬åœ°ç§æœ‰æ•°æ®é›†ï¼ŒloRA rank=8ï¼Œä½¿ç”¨åŸºæ¨¡è¿›è¡ŒSFT
- ç§Ÿæˆ·Bï¼šä½¿ç”¨è¿œç«¯åŠ è½½Hubç«¯å¼€æºæ•°æ®é›†ï¼ŒLoRA rank=32ï¼Œä½¿ç”¨åŸºæ¨¡è¿›è¡ŒPT
- ç§Ÿæˆ·Cï¼šä½¿ç”¨åŸºæ¨¡è¿›è¡ŒGRPO Lossè®¡ç®—ï¼Œä½¿ç”¨Sampleré‡‡æ ·
- ç§Ÿæˆ·Dï¼šä½¿ç”¨åŸºæ¨¡è¿›è¡Œlogpsæ¨ç†

è¿™äº›è¿‡ç¨‹å¯ä»¥åŒæ—¶å‘ç”Ÿåœ¨ä¸€ä¸ªåŸºæ¨¡ä¸Šï¼Œå› ä¸ºæ¨¡å‹ã€Sampleræœ¬è´¨ä¸Šä¹Ÿæ˜¯twinkleç»„ä»¶çš„ä¸€éƒ¨åˆ†ï¼Œå¯ä»¥åšåˆ°ä»»åŠ¡æ— å…³ã€‚è®­ç»ƒå®Œæˆåï¼Œæ”¯æŒcheckpointæ¨é€HuggingFace/ModelScopeçš„æ¨¡å‹ä»“åº“ï¼Œé»˜è®¤ä¸ºç§æœ‰ã€‚twinkleæä¾›äº†å®Œæ•´çš„å¤šç§Ÿæˆ·è®­ç»ƒè§£å†³æ–¹æ¡ˆï¼Œåœ¨serverç«¯æ”¯æŒé›†ç¾¤åŒ–ç®¡ç†å’ŒåŠ¨æ€æ‰©ç¼©å®¹ï¼Œå¯ä»¥è¿›è¡Œç®€å•å®šåˆ¶åŒ–åä½œä¸ºä¼ä¸šçº§æœåŠ¡ã€‚

> ä½œä¸ºæ¨¡å—åŒ–æ¡†æ¶ï¼Œtwinkleæœ¬èº«ä¹Ÿå¯ä»¥æ”¯æŒè¿œç«¯ä¸´æ—¶çš„ç‹¬å å¼è®­ç»ƒï¼Œå³å…¨å‚æ•°æ–¹å¼ã€‚


## æ”¯æŒçš„ç»„ä»¶

<table>
  <tr>
    <td align="center"><b>Dataset</b><br><sub>æ•°æ®åŠ è½½å’Œé¢„å¤„ç†</sub></td>
    <td align="center"><b>Template</b><br><sub>ç¼–ç å’Œè§£ç </sub></td>
    <td align="center"><b>DataLoader</b><br><sub>æ•°æ®åˆ†å‘å’ŒbatchåŒ–</sub></td>
    <td align="center"><b>Preprocessor</b><br><sub>æ•°æ®ETL</sub></td>
    <td align="center"><b>InputProcessor</b><br><sub>å¤„ç†ä»»åŠ¡ç‰¹å®šè¾“å…¥</sub></td>
  </tr>
  <tr>
    <td align="center"><b>Model</b><br><sub>å¤§æ¨¡å‹ï¼Œæ”¯æŒå¤šç§æ¡†æ¶</sub></td>
    <td align="center"><b>Sampler</b><br><sub>é‡‡æ ·å™¨</sub></td>
    <td align="center"><b>Loss</b><br><sub>æ®‹å·®</sub></td>
    <td align="center"><b>Metric</b><br><sub>è®­ç»ƒæŒ‡æ ‡é›†åˆ</sub></td>
    <td align="center"><b>Reward</b><br><sub>å¥–åŠ±å‡½æ•°</sub></td>
  </tr>
  <tr>
    <td align="center"><b>Advantage</b><br><sub>ä¼˜åŠ¿å‡½æ•°</sub></td>
    <td align="center"><b>CheckpointEngine</b><br><sub>æƒé‡åŒæ­¥</sub></td>
    <td align="center"><b>Patch</b><br><sub>è¡¥ä¸ï¼Œç”¨äºæ¨¡å‹ä¿®å¤</sub></td>
    <td align="center"><b>Module</b><br><sub>ç»„ä»¶ï¼Œä¾‹å¦‚Optimizer</sub></td>
    <td align="center"><b>Kernel</b><br><sub>ç®—å­</sub></td>
  </tr>
  <tr>
    <td align="center"><b>Server</b><br><sub>å¼€å¯åç«¯é›†ç¾¤</sub></td>
    <td align="center"><b>Client</b><br><sub>å®¢æˆ·ç«¯ä»£ç </sub></td>
    <td align="center"><b>Infra</b><br><sub>éš”ç¦»rayå’Œtorchrunå·®å¼‚</sub></td>
    <td align="center"><b>Plugin</b><br><sub>ä½¿ç”¨hubç«¯ç»„ä»¶</sub></td>
    <td align="center"><b>Hub</b><br><sub>å¯¹æ¥HF/MSç½‘ç»œåº“</sub></td>
  </tr>
</table>

## ç¤¾åŒºç»„ä»¶

| ç»„ä»¶ç±»å‹ | ç»„ä»¶é“¾æ¥                                                                                                 | ç»„ä»¶ä½œç”¨                                                          | ä½œè€…           |
| -------- | -------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------- | -------------- |
| Patch    | [qwen3_moe_transformers4_patch](https://www.modelscope.cn/models/twinkle-kit/qwen3_moe_transformers4_patch) | ä¿®å¤Qwen3 MoEæ¨¡å‹åœ¨FSDP2è®­ç»ƒæ—¶Hangçš„é—®é¢˜ï¼Œå¯¹transformers==4.xç”Ÿæ•ˆ | ModelScopeå®˜æ–¹ |
