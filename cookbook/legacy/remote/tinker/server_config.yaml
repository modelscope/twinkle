server_type: tinker
proxy_location: EveryNode
http_options:
  host: 0.0.0.0
  port: 8000

applications:
  - name: server
    route_prefix: /api/v1
    import_path: server
    args:

    deployments:
      - name: TinkerCompatServer
        autoscaling_config:
          min_replicas: 1
          max_replicas: 1
          target_ongoing_requests: 128
        ray_actor_options:
          num_cpus: 0.1
        logging_config:
          log_level: DEBUG

  - name: models-Qwen2.5-0.5B-Instruct
    route_prefix: /api/v1/model/Qwen/Qwen2.5-0.5B-Instruct
    import_path: model
    args:
      model_id: "ms://Qwen/Qwen2.5-0.5B-Instruct"
      nproc_per_node: 2
      device_group:
        name: model
        ranks: [0, 1]
        device_type: cuda
      device_mesh:
        device_type: cuda
        mesh: [0, 1]
        mesh_dim_names: ['dp']
    deployments:
      - name: ModelManagement
        autoscaling_config:
          min_replicas: 1
          max_replicas: 1
          target_ongoing_requests: 16
        ray_actor_options:
          num_cpus: 0.1
        logging_config:
          log_level: DEBUG

  # Example: Add more models as needed
  # - name: models-Qwen2.5-7B-Instruct
  #   route_prefix: /api/v1/model/Qwen/Qwen2.5-7B-Instruct
  #   import_path: main:build_model_app
  #   args:
  #     model_id: "ms://Qwen/Qwen2.5-7B-Instruct"
  #     nproc_per_node: 4
  #     device_group:
  #       name: model7b
  #       ranks: [2, 3, 4, 5]
  #       device_type: cuda
  #     device_mesh:
  #       device_type: cuda
  #       mesh: [2, 3, 4, 5]
  #       mesh_dim_names: ['dp']
  #   deployments:
  #     - name: ModelManagement
  #       autoscaling_config:
  #         min_replicas: 1
  #         max_replicas: 1
  #         target_ongoing_requests: 16
  #       ray_actor_options:
  #         num_cpus: 0.1
  #       logging_config:
  #         log_level: DEBUG

